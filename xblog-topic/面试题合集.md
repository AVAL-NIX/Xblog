---
submitToken: 0EE6154490B9E493BFE64799D89D8E1518CB133FF16A8F2250E224BD20A47640
title: 面试题合集
channel: topic
labels: java
---

# 自我介绍 项目(2分钟)

面试官你好，我是郑新，今年在JAVA行业工作有5年多了，主要用spring体系， 掌握JVM,JUC等JAVA技术栈， 待过的公司主要介绍一下EIMS是做P2P项目，主要是做借贷业务的。 现金贷的评分模型。 对接很多过第3方支付 （汇付天下，宜宾银行之类的各种各种第3方银行）。还有电子合同之类的业务。然后就是现在做的这个项目主要是做应急指挥系统的。 最大的应用场景是南山区的平安深圳项目了。主要设计了与客户端的交互。模仿spring采用了JAVA注解来映射指令的。

# 项目中最大的挑战，花费最长时间的项目，比较有成就感的事情

探索视频播放流程，花费最长的项目是应急了，做了1年多。项目验收的那一刻最有成就感。

# 项目中印象最深的bug

服务器采用0时区， 我们开发电脑跟数据库采用东八区， 因为存的是时间戳， 导致出问题了。

# 分别用3个词描述自己的优缺点

# == 与 equals 的区别

== 比较的值 ， 就是内容。 Equals比较的是地址

# JAVA 中 BIO，NIO, AIO区别

- 同步阻塞IO (BIO)

用户态需要等待内核态返回消息

- 同步非阻塞IO (NIO）

用户态不需要等待内核态返回消息，但是需要不断轮训内核态，浪费CPU资源

- IO多路复用（JAVA中的NIO）

如何避免同步非阻塞IO模型中轮询等待的问题呢？

答案是采用IO多路复用模型。

目前支持IO多路复用的系统调用有select、poll,epoll等。几乎所有的操作系统都支持select系统调用，

它具有良好的跨平台特性。epoll是在Linux 2.6内核中提出的，是select系统调用的Linux增强版本。在IO多路复用模型中通过select/epoll系统调用，单个应用程序的线程可以不断地轮询成百上千的socket连接的就绪状态，当某个或者某些socket网络连接有IO就绪状态时就返回这些就绪的状态（或者说就绪事件）。

举个例子来说明IO多路复用模型的流程。发起一个多路复用IO的read操作的系统调用，流程如下：

（1）选择器注册。首先，将需要read操作的目标文件描述符（socket连接）提前注册到Linux的select/epoll选择器中，在Java中所对应的选择器类是Selector类。然后，开启整个IO多路复用模型的轮询流程。

（2）就绪状态的轮询。通过选择器的查询方法，查询所有提前注册过的目标文件描述符（socket连接）的IO就绪状态。通过查询的系统调用，内核会返回一个就绪的socket列表。当任何一个注册过的socket中的数据准备好或者就绪了就说明内核缓冲区有数据了，内核将该socket加入就绪的列表中，并且返回就绪事件。

（3）用户线程获得了就绪状态的列表后，根据其中的socket连接发起read系统调用，用户线程阻塞。内核开始复制数据，将数据从内核缓冲区复制到用户缓冲区。

（4）复制完成后，内核返回结果，用户线程才会解除阻塞的状态，用户线程读取到了数据，继续执行。

![](https://image.avalon-zheng.xin/0d549bff-0a90-43b4-bbf2-8d2d2195e7e6 "")

> 在多路复用IO模型中，会有一个线程（Java中的Selector）不断去轮询多个socket的状态，只有当socket真正有读写事件时，才真正调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。(NIO中会有N个线程去轮训造成CPU资源浪费)

Reactor 模型

- Reactor单线程

![](https://image.avalon-zheng.xin/8dd7c90c-baa2-42a0-94e6-7248708f1b2d "")

每个客户端发起连接请求都会交给acceptor,acceptor根据事件类型交给线程handler处理，注意acceptor 处理和 handler 处理都在一个线程中处理，所以其中某个 handler 阻塞时, 会导致其他所有的 client 的 handler 都得不到执行, 并且更严重的是, handler 的阻塞也会导致整个服务不能接收新的 client 请求(因为 acceptor 也被阻塞了). 因为有这么多的缺陷, 因此单线程Reactor 模型用的比较少.

- Reactor多线程模式

![](https://image.avalon-zheng.xin/a04b94b7-e69a-4224-9683-e55c99f23e99 "")

有专门一个线程, 即 Acceptor 线程用于监听客户端的TCP连接请求.

客户端连接的 IO 操作都是由一个特定的 NIO 线程池负责. 每个客户端连接都与一个特定的 NIO 线程绑定, 因此在这个客户端连接中的所有 IO 操作都是在同一个线程中完成的.

客户端连接有很多, 但是 NIO 线程数是比较少的, 因此一个 NIO 线程可以同时绑定到多个客户端连接中.

缺点：如果我们的服务器需要同时处理大量的客户端连接请求或我们需要在客户端连接时, 进行一些权限的检查, 那么单线程的 Acceptor 很有可能就处理不过来, 造成了大量的客户端不能连接到服务器.

- Reactor主从模式

![](https://image.avalon-zheng.xin/ec18d05e-c1a3-467a-9004-4ee59ff426ab "")

Reactor 的主从多线程模型和 Reactor 多线程模型很类似, 只不过 Reactor 的主从多线程模型的 acceptor 使用了线程池来处理大量的客户端请求.

  异步AIO
![](https://image.avalon-zheng.xin/e9935c0e-f219-4e75-a096-34ec8daadd4e "")

理论上来说，异步IO是真正的异步输入输出，它的吞吐量高于IO多路复用模型的吞吐量。就目前而言，Windows系统下通过IOCP实现了真正的异步IO。在Linux系统下，异步IO模型在2.6版本才引入，JDK对它的支持目前并不完善，因此异步IO在性能上没有明显的优势。大多数高并发服务端的程序都是基于Linux系统的。因而，目前这类高并发网络应用程序的开发大多采用IO多路复用模型。大名鼎鼎的Netty框架使用的就是IO多路复用模型，而不是异步IO模型。

# hashCode 与 equals 的介绍

都是object 中的方法

hashcode : 获取一个哈希码是个 int型

euqls: 判断对象是否相等, 2个对象相等， hashcode一定相等。 2个对象hashcode相等， 但是不一定相等，

hashmap在判断元素是否存在时会先判断hashcode .

重写euqlas要重写hashcode

# 单列模式

- 懒汉
- 饿汉
- 静态内部类
- 枚举

# Integer Cache概念

int 值在-128到127之间， 如果没有new对象
则引用的是常量池里面的对象， 直接用 == 可以 判断， 如果是new Integer(10) 则不可以

> 节省内存，提高效率

# QUEUE 介绍

有几个实现类，用于消峰，异步通知

Deque,

- LinkedList
- ArrayDeque
（常规数组或者链表，没什么特别的。）

BlockingQueue
(线程安全的)

- arrayxxxx
- link xxxxx
- priotrityxxxxx

这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。
请看集合的详细实现。

- ArrayBlockingQueue 底层是数组，有界队列，如果我们要使用生产者-消费者模式，这是非常好的选择。底层ReentrantLock ， condition 去通知

```
    /** Main lock guarding all access */
    final ReentrantLock lock;

    /** Condition for waiting takes */
    private final Condition notEmpty;

    /** Condition for waiting puts */
    private final Condition notFull;
  ```

- LinkedBlockingQueue 底层是链表，可以当做无界和有界队列来使用，所以大家不要以为它就是无界队列。

```
    /** Lock held by take, poll, etc */
    private final ReentrantLock takeLock = new ReentrantLock();

    /** Wait queue for waiting takes */
    private final Condition notEmpty = takeLock.newCondition();

    /** Lock held by put, offer, etc */
    private final ReentrantLock putLock = new ReentrantLock();

    /** Wait queue for waiting puts */
    private final Condition notFull = putLock.newCondition();
```

- SynchronousQueue 本身不带有空间来存储任何元素，使用上可以选择公平模式和非公平模式。就是存储线程。然后进行匹配
- PriorityBlockingQueue 是无界队列，基于数组，数据结构为二叉堆，数组第一个也是树的根节点总是最小值。

> 二叉堆：一颗完全二叉树(数组实现就是二叉堆，链表实现就是二叉树)，它非常适合用数组进行存储，对于数组中的元素 a[i]，其左子节点为 a[2*i+1]，其右子节点为 a[2*i + 2]，其父节点为 a[(i-1)/2]，其堆序性质为，每个节点的值都小于其左右子节点的值。二叉堆中最小的值就是根节点，但是删除根节点是比较麻烦的，因为需要调整树。

# hashMap在1.8的优化

- 拉链法转换成红黑树（自平衡二叉树） 。

你会写红黑树吗？ 不会。。。

性质1：每个节点要么是黑色，要么是红色。
性质2：根节点是黑色。
性质3：每个叶子节点（NIL）是黑色。
性质4：每个红色结点的两个子结点一定都是黑色。
性质5：任意一结点到每个叶子结点的路径都包含数量相同的黑结点。

# ConcurrentHashMap 和 HashTable HashMap 的区别

1. ConcurrentHashMap  HashTable 线程安全的hashMap
2. hashMap 不安全

HashTable 全称锁方法。 效率很低

ConcurrentHashMap 1.7采用分段锁
1.8采用 sync + cas 锁数组下标 。 只要key不冲突就不会发生冲突

# JAVA8 常用新特性

- 提供@FunctionalInterface注解来定义函数式接

- Lambda表达式

- 方法引用  》 配合lambda表达式

- Stream接口  》 分组求和， 过滤

- Optional类  》 用来判断是否为空

# 设计模式

- 单列
- 策略组合
- 工厂模式
- 模板模式

# LIST 源码

# HASH MAP 源码

# linkList 源码

# JVM 内存模型结构

共有

堆：
方法区（元空间）

非共有

栈：
程序计数器
本地方法栈

# 内存溢出跟内存泄漏的区别

 内存溢出： JVM内存不够了。无法分配内存

内存泄漏 ： JVM通过GC无法回收对象

# JVM 垃圾回收， 垃圾回收算法， 垃圾回收期

 JVM 垃圾回收？

 GC ROOT 可达性分析 。

  垃圾回收算法 ？

  年轻代，
  复制算法 。 s0 跟　ｓ1
  老年代
  标记-整理： 性能低，不会产生垃圾碎片
  标记-清除： 会产生碎片垃圾。

1、初试标记
初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快。初始标记的过程是需要触发STW的，不过这个过程非常快，而且初试标记的耗时不会因为堆空间的变大而变慢，是可控的，因此可以忽略这个过程导致的短暂停顿。

2、并发标记
并发标记就是将初始标记的对象进行深度遍历，以这些对象为根，遍历整个对象图，这个过程耗时较长，而且标记的时间会随着堆空间的变大而变长。不过好在这个过程是不会触发STW的，用户线程仍然可以工作，程序依然可以响应，只是程序的性能会受到一点影响。因为GC线程会占用一定的CPU和系统资源，对处理器比较敏感。CMS默认开启的GC线程数是：(CPU核心数+3)/4，当CPU核心数超过4个时，GC线程会占用不到25%的CPU资源，如果CPU数不足4个，GC线程对程序的影响就会非常大，导致程序的性能大幅降低。

3、重新标记
由于并发标记时，用户线程仍在运行，这意味着并发标记期间，用户线程有可能改变了对象间的引用关系，可能会发生两种情况：一种是原本不能被回收的对象，现在可以被回收了，另一种是原本可以被回收的对象，现在不能被回收了。针对这两种情况，CMS需要暂停用户线程，进行一次重新标记。

4、并发清理
重新标记完成后，就可以并发清理了。这个过程耗时也比较长，且清理的开销会随着堆空间的变大而变大。不过好在这个过程也是不需要STW的，用户线程依然可以正常运行，程序不会卡顿，不过和并发标记一样，清理时GC线程依然要占用一定的CPU和系统资源，会导致程序的性能降低。

# JVM 调优

1. 先看看机器内存。 一般是机器内存的80%

XMS XMX 2个值我会调整成一样。 。 堆值保证不会变化
Xmn 年轻代的值怎么说呢。 要看情况了。 。。。
先根据代码并发量 ， 统计接口每秒调用次数，
然后统计一个方法大概要多少MB空间。  然后防止对象从 sur区直接跑到老年区去。
年轻代也是可以调整比老年代大的。因为大对象是直接跑到老年代去的麻 。
然后也可以通过阿里的监控插件（Arthas）。

# 类加载器和类加载过程

类加载器 ： 3个， boot , app , ext

boot：加载了java下所有java (rt.jar)
app:

类加载过程

加载- 》 连接 -> 初始化 （类构造器<clinit>()方法） -》 适用 - 》卸载+

# 　线程和进程

线程：系统调度最小单位
进程: 系统运行最小单位

一个进程至少有一个线程

# 线程生明周期

新建 ， 就绪 ， 运行， 阻塞， 死亡。

# 线程池理解

优点： 可以 节约线程资源。 。
2. 提高响应速度。 没有创建跟销毁过程。 。
3. 方便统一管理

底层原理

底层原理是把一个线程丢进队列。由核心线程池去异步运行。  然后没有跑start , 跑的run方法。

6大参数

核心线程数
最大线程数。
空闲销毁时间。
销毁时间单位

策略模式

- 直接抛出异常 。 abortPolicy
- 丢弃任务。
- 丢弃队列中靠前的任务
- 直接新建线程运行。callerrunspolicy
队列模式

# ThreadLocal 原理分析

允许不同的线程创建
。。。。

# sync , lock

# volatile , atomic

# 锁升级

# striped64 +Longaddr

1. 如何提高CAS性能？
2. CPU总线风暴是什么？
3. LongAdder的核心思想是什么？和ConcurrentHaspMap的分段锁对比？
4. LongAdder和AutomicLong性能比较
5. LongAdder的原理是什么？
6. LongAdder实例的内部结构？
7. 基类Striped64内部三个重要的成员？

- Cell数组
- base 基础变量
- cellsBusy 自旋锁

8. LongAdder类的add()方法源码解析
9. 伪共享是什么？缓存行带来的问题？如何解决？

伪共享的非标准定义为：缓存系统中是以缓存行（cache line）为单位存储的，当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。

longadder
内部是用了一个数组分散热点 。 。
取值的时候将数组求和就好了。

# redis 支持数据类型

1. string ,
2. map
3. list
4. set
5. sort set
6. bitmap

7.

# redis 主从， 哨兵， 集群区别

主从： 内容只在主上面。 从是复制。
哨兵：哨兵支持多主多从， 但是每台服务器上内容是一样的。 受空间限制。
集群：

# 分布式锁

几种。

# redis雪崩跟穿透解决方案

雪崩。 设置KEY 永不过时。 或者打乱

穿透的话，boolean

# redis sorted set 结构

skiplist  ,=链表

有序集合保存的元素数量小于128个
有序集合保存的所有元素的长度小于64字节
情况下使用
ziplist = 紧紧埃着的数组。 前后有长度偏移标识

# ACID 的理解

原子性（Atomicity）
原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。
一致性（Consistency）
事务前后数据的完整性必须保持一致。
隔离性（Isolation）
事务的隔离性是多个用户并发访问数据库时，数据库为每一个用户开启的事务，不能被其他事务的操作数据所干扰，多个并发事务之间要相互隔离。
持久性（Durability）
持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来即使数据库发生故障也不应该对其有任何影响

# 事物隔离级别

读未提交
读提交
可重复读
串行化

# 锁机制与INNODB锁算法

# mysql常用索引 （慢SQL优化方案）

主键索引被称为聚合索引

# 大表优化 。。 （限制查询范围，读写分离，垂直分离，水平分表）

# MYSQL底层数据结构

frm文件是存放的表结构，表的定义信息；

*.ibd文件是存放着表中的数据、索引信息；

B+树

InnoDB存储引擎的非主键索引最底层叶节点存储的是索引信息及指向主键索引的指针信息。

# zookeeper常用使用场景

- 命名服务

- 集群管理

服务注册于发现，负载均衡

- 配置管理

- 分布式锁

- 队列管理

# zookeeper底层数据结构与znode介绍

ZooKeeper 会维护一个具有层次关系的数据结构，它非常类似于一个标准的文件系统：

## 数据结构

每个Znode由3部分组成:

stat：此为状态信息, 描述该Znode的版本, 权限等信息
data：与该Znode关联的数据
children：该Znode下的子节点

> 限制每个Znode的数据大小至多1M

## 节点类型

 分为临时节点，永久节点

## 数据访问

ACL 控制列表

## Zxid

Zxid是一个64为的数字

cZxid： 是节点的创建时间所对应的Zxid格式时间戳。

mZxid：是节点的修改时间所对应的Zxid格式时间戳。

实现中Zxid是一个64为的数字，它高32位是epoch用来标识Leader关系是否改变，每次一个Leader被选出来，它都会有一个新的epoch。低32位是个递增计数。

## 版本号

version：节点数据版本号

cversion：子节点版本号

aversion：节点所拥有的ACL版本号

## watcher机制

ZooKeeper允许用户在指定节点上注册一些Watcher，当数据节点发生变化的时候，ZooKeeper服务器会把这个变化的通知发送给感兴趣的客户端。这个是 ZooKeeper 的核心特性，

# zookeeper 通知机制

watch事件理解：

一次触发（one-time-trigger）：当数据有了变化时，zookeeperserver向客户端发送一个watch，他是一次性动作，即触发一次就不再有效，类似一次性纸杯。
只监控一次
如果想继续watch的话，需要客户端重新设置watcher。所以如果你得到一个watch事件且想在将来的变化继续得到通知，必须设置另一个watch。

发往客户端：watches是异步发往客户端的，zookeeper提供了一个顺序保证，在看到watch事件之前绝不会看到变化，这样不同客户端看到的是一致性的顺序：
在导致watch事件触发的操作成功码返回到达客户端之前，事件可能在去客户端的路上，但是可能不会到达客户端。观察事件是异步的发送给观察者（客户端）的，zookeeper会保证次序：在收到观察事件之前，客户端不会看到已经为之设置观察的节点的改动。网络延迟或者其他因素可能会让不同的客户端在不同的时间收到观察事件和操作的返回码，这里的要点是：不同客户端看到的事情都有一致的次序

为数据设置watch：数据观察和子节点观察，getData()和exists()设置数据观察，getChildren()设置子节点观察。
setData()将为znode触发数据观察，成功的create()将为新创建的节点触发数据观察，为其父节点触发子节点观察，成功的delete()将会为被删除的节点触发数据观察以及子节点观察（因为节点不能再有子节点了），为其父节点出发子节点观察
观察维护在zookeeper服务器中，客户端连接到新的服务器时，所有的会话事件将被触发，同服务器断开连接期间不会收到观察；客户端重新连接时，如果需要，先前已经注册的观察将被重新注册和触发。有一种情况下观察事件将丢失：对还没有创建的节点设置存在观察，而在断开连接期间创建节点，然后删除

# zookeeper分布式锁

核心实现 核心代码部分就是实现上述介绍过程中的实现分布式锁的逻辑。每个线程在调用getDisLock方法获取锁的时候，首先都需要去zk某一指定目录下创建一个有序的临时节点，然后获取到目录下序号最小的节点判断是不是自己刚刚创建的那个节点。如果是，则说明该线程可以获取到锁，如果不是，则需要设置监听器，去监听其上一个节点的状态。如果其上一个节点发生变化，说明上一个节点代表的线程执行结束，则该节点可以解除等待并重新执行尝试获取锁的操作，然后再重复执行上面的过程获取目录下序号最小的几点判断是不是自己的，如果是，则该线程获取到锁。

# zookeeper队列实现

（1）同步队列
当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。例如一个班去旅游，看是否所有人都到齐了，到齐了就发车。例如有个大任务分解为多个子任务，要所有子任务都完成了才能进入到下一流程。

  阻塞队列的实现利用了CountDownLatch 的特性。当子节点数量为0时，即队列中没有元素，这是线程在此等待，同时监听子节点的变化，如果有数据入队，则从等待返回，取出数据。

> CountDownLatch（100） 如果有有入队， 则进行watch监听通知减少1。

（2）先进先出队列
按照FIFO方式进行入队和出队

在zookeeper中先创建一个根目录 queue_fifo，做为队列。入队操作就是在queue_fifo下创建自增序的子节点，并把数据放入节点内。出队操作就是先找到queue_fifo下序号最下的那个节点，取出数据，然后删除此节点。

# zookeeper集群内部机器一致原理

由于在设计分布式架构时，需要根据业务反复权衡可用性和数据一致性，因此产生了一系列的一致性协议算法，其中最著名的就是二阶段提交（2PC）、三阶段提交（3PC）和Paxos算法。

## 2PC

2PC将事务提交分为两个阶段：发起事务请求和事务提交/回滚

发起事务请求
首先协调者向各参与者发送事务内容，询问是否可以执行事务提交，并等待参与者的反馈。
然后各参与者开始执行事务，并记录事务日志信息。
最后各参与者向协调者反馈事务执行的结果，成功或者失败。
事务提交/回滚
在该阶段中，协调者根据参与者的反馈决定是否真正提交事务，只要有一个参与者反馈的是“失败”或者等待反馈超时，那么协调者就会通知各参与者回滚之前的事务操作；否则，通知参与者提交事务。参与者执行完成后会反馈协调者一个ACK，协调者收到所有的参与者ACK后，完成事务的提交或中断。

以上就是2PC的执行过程，其中一阶段可以看作是一个投票过程，二阶段则是执行投票的结果。因为需要等待参与者的“全票通过”，因此2PC是一个强一致性的协议算法。
2PC原理简单，实现容易，但同时也存在很多的问题：

同步阻塞：在整个二阶段提交的过程中，参与者在释放占用资源之前（提交或终止完成），是处于同步阻塞的，无法处理其它任何操作，极大地影响了系统的性能。
单点故障：由上可知，协调者在整个过程中非常的重要，一旦出现问题，整个协议就无法运转了。
数据不一致：当在第二个阶段，协调者正在发出提交请求，此时网络出现故障或者协调者自身崩溃导致只有一部分参与者收到提交请求，那么数据就会出现不一致。
过于保守：在事务询问阶段，如果任一参与者在反馈协调者之前出现故障而导致协调者无法收到反馈，那么协调者就会一直处于阻塞状态，只能通过自身的超时机制来判断是否要中断事务。

## 3PC

3PC则是对2PC的改进，将发起事务请求阶段一分为二，因此包含了三个阶段：事务询问（canCommit）、事务预提交（preCommit）和提交事务（doCommit）。

canCommit
协调者向所有参与者发送一个包含事务内容的询问请求，等待参与者的反馈。
参与者收到请求后，根据自身情况返回"YES"或"NO"。
preCommit
协调者根据参与者的反馈情况来通知参与者预提交事务或者中断事务：

预提交事务：协调者收到的都是“YES”反馈，就会通知参与者进行事务的预提交，并记录事务日志，参与者执行预提交完成后，将结果反馈给协调者。
中断事务：若一阶段中任一参与者反馈的是“NO”，或者协调者等待反馈超时，那么协调者就会发出中止请求，此时无论参与者是收到中止请求或是等待请求超时，参与者都会中断事务。
doCommit
协调者根据二阶段参与者的反馈来通知参与者提交事务或者回滚事务：

提交事务：二阶段中所有参与者预提交事务成功，则在此阶段真正地提交事务。
回滚事务：二阶段中任一参与者预提交事务失败，则在此阶段根据事务日志回滚事务。
需要注意的是，在此阶段，可能会出现以下故障：

协调者出现故障
协调者和参与者之间通信故障
无论是哪种故障，都是导致参与者无法接收到协调者发出的请求，针对这种情况，参与者在等待请求超时后，都会继续提交事务（不能回滚，因为协调者可能已经提交事务，若参与者回滚事务就会导致数据不一致）。

通过以上过程，我们可以发现，3PC相较于2PC的优点：

降低了阻塞的范围，3PC要到阶段二才会出现阻塞，而2PC在整个提交过程中都是阻塞的。
在阶段三出现单点故障后能够保证数据的一致性
但在优化阻塞问题的同时带来了新的问题，当参与者收到preCommit请求后出现网络分区，那么断开连接的参与者会继续提交事务，而协调者由于未收到全部参与者的“YES”反馈，就会向保持连接的参与者发出中断事务的请求，导致数据出现不一致。
因此，我们可以看出无论是2PC还是3PC都无法完全解决数据一致性问题，并且整个事务提交过程太过保守，导致性能并不是很好。所以，Paxos算法也就出现了。

 C：Consistency，一致性，数据一致更新，所有数据变动都是同步的。

② A：Availability，可用性，系统具有好的响应性能。

③ P：Partition tolerance，分区容错性。以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在C和A之间做出选择，也就是说无论任何消息丢失，系统都可用。

我们知道ZooKeeper也是一种分布式系统，它在一致性上有人认为它提供的是一种强一致性的服务（通过sync操作），也有人认为是单调一致性（更新时的大多说概念），还有人为是最终一致性（顺序一致性），反正各有各的道理这里就不在争辩了。然后它在分区容错性和可用性上做了一定折中，这和CAP理论是吻合的。ZooKeeper从以下几点保证了数据的一致性

顺序一致性：同一客户端的事务请求按照“先入先出”的方式处理，保证了事务执行的顺序。
原子性：集群情况下，保证事务要么都被所有机器执行，要么都不执行，不存在部分执行部分不执行的情况。
最终一致性：客户端从服务端获取的数据不一定是实时最新的，但是能保证在一定的时间内服务端数据达到最终一致性，即客户端最终能获取到最新的数据。
共享视图：无论客户端连接的是哪个服务端，获取到的数据都是一样的，不存在特例。
可靠性：一旦一个事务被执行成功且正确的返回给了客户端，那么这个事务结果就会持久化存在并共享给所有服务器节点，除非有新的事务更改了该事务的结果。

> zookeeper  是AP

# Zookeeper一致性协议ZAB

Zookeeper在保证数据一致性上并未完全基于Paxos实现，而是使用了其特定的ZAB原子广播协议，支持崩溃恢复和消息广播。下面就来看看ZAB的实现原理吧。

实现原理
ZAB协议是一个类2PC的协议，也是分两步提交，它包含了两个模式：消息广播和崩溃恢复。

消息广播
Zookeeper集群在启动时会选择出一个Leader服务器用于处理事务请求，当客户端发起事务请求时，若收到请求的服务器不是Leader，就会将请求转发给Leader服务器，该服务器会给创建一个事务Proposal并广播给所有的Follower服务器（Proposal需要保证顺序性，而Zookeeper是基于TCP实现的长连接，天然具有FIFO特性，同时Leader服务器会为每一个Proposal分配一个全局递增的唯一ID(ZXID)，以及为每一个Follower服务器都创建一个单独的队列，然后将这些Proposal按照ZXID的先后顺序放入到队列中等待Follower服务器处理。），然后再收集各个服务器的投票信息，当有过半的服务器反馈的是“肯定”选票，Leader服务器就会再广播一个commit请求提交事务，同时自身也提交该事务，这就是消息广播模式。
这个过程看起来好像和我们上文所说的2PC没什么区别，但实际上，Zookeeper的消息广播移除了二阶段提交中的中断逻辑，这就意味着Leader服务器不必再等待集群中其它所有服务器的反馈，只要有过半的服务器给出了正常的反馈（这就是为什么集群需要保证存活服务器数量过半才能对外提供服务的原因），就广播commit请求；反观Follower服务器，也只需要给出正常的反馈或者直接丢弃掉该Proposal。这样就解决了同步阻塞的问题，处理更加简单了，但是无法解决Leader服务器由于崩溃退出而导致的数据不一致问题，因此，就需要崩溃恢复模式来解决该问题。

崩溃恢复
消息广播模式在Leader服务器运行正常的情况下表现良好，但是刚刚也说了一旦Leader服务器崩溃，或者网络分区导致该Leader服务器失去了过半服务器的支持，此时集群就会进入崩溃恢复模式，重新选举Leader。重新选举Leader需要保证两个特性：

已经在Leader服务器上提交的事务最终需要所有的服务器都提交。很好理解，当有过半服务器给出反馈后，Leader服务器就会提交自身的事务，并广播commit请求给所有服务器，但在此之前Leader服务器挂了，那么如果不满足该特性必然就会出现数据的不一致。
需要确保丢弃那些只在Leader服务器上被提出的事务。在Leader服务器提出Proposal还未发送给其它服务器时，该服务器挂了，而后，该服务器恢复正常加入到集群中时，必然要丢弃掉该事务才能达到数据一致。
只有这两个特性都被满足，数据才能达到最终一致。但是要如何做到这一点呢？这就需要用到上文提及的ZXID。那什么是ZXID？它是一个64位的编号，分为高32位和低32位。高32位是“朝代”编号，即每进行一轮Leader选举，该编号就会自增1；低32位是当前“朝代”数据更新次数，即每生成一个Proposal，该编号就会自增1，若“更朝换代”，该编号会重置为0。
有了这个编号后，当Leader服务器挂掉，剩余服务器重新选举Leader时，只需要将拥有最大ZXID编号的的服务器作为新的Leader服务器即可保证数据的一致性。这个不难理解，若Leader服务器是已经广播commit后挂掉的，那么肯定有服务器已经拥有了最新的Proposal，即最大的ZXID，那么将该服务器作为Leader，其它服务器只需要同步该服务器上的数据即可达到数据一致；若Leader服务器创建了Proposal但未广播就挂掉了，则此时剩余服务器并不会拥有该Proposal的ZXID，当挂掉服务器恢复后，此时，该集群中已经有新的Leader，也就是之前未广播的Proposal的ZXID肯定不会大于当前Leader拥有的ZXID，所以直接丢弃即可。

# Leader选举详解

Zookeeper选举Leader分为启动时选举和服务运行期间的选举。在往下看之前需要先了解服务器的几个状态：

LOOKING：观望状态，此时还未选举出Leader
LEADING：该服务器为Leader
FOLLOWING：该服务器为Follower
OBSERVING：该服务器为Observer
在构建Zookeeper集群时，最少服务器数量是2，但是服务器数量最好为奇数（因为需要过半服务器的支持才能完成投票和决策，如果是6台，那么最多允许挂掉2台服务器，存活4台进行投票决策；而如果是5台，那么最多允许挂掉的台数也是2台，但是只有3台进行投票决策。因此，相比较而言，奇数台服务器数量容错率更高的同时还降低了网络通信负担），因此，这里使用3台服务器说明，分别是server1、server2、server3。

启动时选举
启动服务器，当选举完成前，所有服务器的状态都是LOOKING。当启动server1（我们假设其myid为1，myid就是服务器id，需要自己配置，后面实际操作时会讲）时，一台服务器无法完成选举，因为需要过半服务器；然后启动server2（假设myid为2），这时两台服务器开始通信，并进入选举流程竞选Leader。

首先每台服务器都会将自己的myid和ZXID作为投票发送给其它服务器，因为是第一轮投票，所以假设ZXID都会0，那么server1的投票为（1，0），server2的投票为（2， 0）
服务器接收其它服务器的投票并检测投票是否有效，包括是否为同一轮投票，以及是否来自于LOOKING服务器
检验通过后，每个服务器都会将自己的投票和收到的投票进行比较。首先比较ZXID，选出最大的并更新为自己新的一轮投票，这里ZXID都是一样的，所以继续比较myid，同样选出最大的作为自己新的一轮投票。因此，这里server1会更新自己的投票为（2，0），而server2则是将自己之前的投票再重新投一次即可。
每一轮投票结束后，服务器都会统计投票信息，看看是否已经有服务器受到过半服务器的支持，若有，就将其作为Leader服务器，并将状态修改为LEADING，其它服务器状态则变为FOLLOWING。这里就是server2成为了Leader，选举结束。
当server3启动时，发现集群中已经存在Leader，则只需作为Follower服务器将入进去即可，不需要重新选举，除非Leader服务器挂掉。

服务运行期间的选举
服务运行期间Leader的选举其实在崩溃恢复那一节已经提及到，这里再详细说说。

当server2服务器崩溃时，剩余服务器因为找不到Leader，就会将自己的状态更新为LOOKING并进入Leader选举流程，这时候服务是不可用的。
存活服务器都会生成投票信息，因为服务已经运行一段时间，所以ZXID可能是不一样的，我们假设server1的投票为（1， 10），server3的投票为（3，11）。后面的流程就会启动时的选举是一样的了，只不过，server1在收到（3，11）投票后，只要比较ZXID即可。所以最终确定server3为新的LEADER。

# 消息队列

## 消息模型

- 点对点

消息生产者生产消息发送到 queue中，然后消息消费者从queue中取出并且消费消息。这里要注意：
消息被消费以后，queue中不再有存储，所以消息消费者不可能消费到已经被消费的消息。
Queue支持存在多个消费者，但是 对一个消息而言，只会有一个消费者可以消费。

- 发布/订阅

消息生产者（发布）将消息发布到topic中，同时有多个消息消费者（订阅）消费该消息。和点对点方式不同，发布到topic的消息会被所有订阅者消费。

## 使用场景

- 异步处理

把一些不重要的业务通过MQ异步的处理，如发短信

- 应用解耦

订单服务如果调用库存服务，会导致有可能失败，
如果通过MQ 就可以经过异步的库存出库了。 。

- 流量削锋

通过MQ队列作为缓冲， 控制秒杀人数，多出来的人数通过其他页面展示

- 日记采集

KAFAKA

# JMS和AMQP的区别

1 通信平台的区别

JMS:  只允许基于JAVA实现的消息平台的之间进行通信
AMQP: 允许多种消息协议进行通信,比如ruby的storm和java的jms都可以在AMQP上进行通信。
结论: AMQP允许多种技术同时进行协议通信

2 通信机制的区别
JMS:消息生产者和消息消费者必须知道对方的Queue
AMQP: 消息生产者和消息消费者无须知道对方的Queue,消息生产者将Exchange通过Route key和任意Queue绑定。消息消费者通过Route key从任意Queue中获取Exchange.

3 消息传输机制的区别
JMS:JMS支持PTP和publis/subscribe机制,PTP只可以点对点通信,public/subscribe在一端发出请求后所有其他端收到消息
AMQP:1 所有RouteKey相同的Queue接受到数据
             2 所有相同的Exchange的Queue接受到数据
             3 所有wilecard的Exchange的Queue接

# 手画rabbitmq,kafka等流程图

# 消息堆积怎么处理

# rabbitmq,kafka源码

# spring

spring core

spring aspects

spring aop

spring jdbc

spring web

# 分布式事务方案

2pc
3pc
ttc
seata

# 分布式锁方案

set+lua
setnx
rediesonLock

# cap的理解

Consistency（一致性）
Availability（可用性）
Partition tolerance（分区容忍性）

# 微服务优点，特点

相比于传统集中式的应用系统，微服务的优点：

每个服务独立存在，所以可以单独部署，不用每次发布某个功能都经历一次全服务发布。

遵循单一功能原则，服务之间可以通过RESTFUL或者RPC调用，功能解藕

“细粒度” 的高可扩展性，每个服务都可以单独扩展，单独负载均衡

有利于简化单独的开发测试以及部署，对开发团队友好

微服务缺点：

服务的可用性和维护性高度依赖于服务治理，如果治理得不好将会是灾难

某些服务可能造成性能瓶颈，某些服务的宕机可能导致很多服务受影响

服务配置繁琐

# resultful,soap,rpc,soa,微服务之间的区别？

resultful：接口风格
soap: XML数据格式传输协议
rpc:远程接口调用

1.SOA（Service Oriented Architecture）“面向服务的架构”:他是一种设计方法，其中包含多个服务， 服务之间通过相互依赖最终提供一系列的功能。一个服务 通常以独立的形式存在于操作系统进程中。各个服务之间 通过网络调用。

2.微服务架构:其实和 SOA 架构类似，微服务是在 SOA 上做的升华，微服务架构强调的一个重点是“业务需要彻底的组件化和服务化”，原有的单个业务系统会拆分为多个可以独立开发、设计、运行的小应用。这些小应用之间通过服务完成交互和集成。

微服务架构 = 80%的SOA服务架构思想 + 100%的组件化架构思想 + 80%的领域建模思想

# springboot最大优势是什么

(1)简化配置，不需要编写太多的xml配置文件；

(2)基于Spring构建，使开发者快速入门，门槛很低；

(3)SpringBoot可以创建独立运行的应用而不需要依赖于容器；

(4)内置tomcat服务器，不需要打包成war包，可以直接放到tomcat中运行；

(5)提供maven极简配置，以及可视化的相关监控功能，比如性能监控，应用的健康程度等；

(6)为微服务SpringCloud奠定了基础，使得微服务的构建变得简单；

(7)Spring可以整合很多各式各样的框架，并能很好的集成；

(8)活跃的社区与论坛，以及丰富的开发文档；

# springboot的条件注解有那些？对应什么逻辑处理

@ConditionalOnBean、ConditionalOnMissingBean

@ConditionalOnClass、ConditionalOnMissingClass

@ConditionalOnExpression、

@ConditionalOnMissingBean等。

refresh阶段开始解析

# 是否可以在springboot中覆盖或者嵌入TOMCAT

是的，可以使用starter依赖项将嵌入式Tomcat替换为任何其他服务器。可以根据需要使用SpringBootStarter Jetty或SpringBootStarter作为每个项目的依赖项。可以在Spring Boot application中禁用默认的Web服务器吗？

Spring的主要优势是提供灵活性来构建松散耦合的应用程序。Spring提供了在快速配置中禁用网络服务器的功能。可以使用应用程序属性来配置网络应用程序类型，例如 spring.main.web-application-type=none.

# springboot starter的工作原理？ spi?

先讲双亲委派模型

在讲SPI如何实现

什么是双亲委派？
如果一个类加载器收到了加载某个类的请求,则该类加载器并不会去加载该类,而是把这个请求委派给父类加载器,每一个层次的类加载器都是如此,因此所有的类加载请求最终都会传送到顶端的启动类加载器;只有当父类加载器在其搜索范围内无法找到所需的类,并将该结果反馈给子类加载器,子类加载器会尝试去自己加载。
双亲委派模型，是一种加载类的约定。这个约定的一个用处是保证安全。比如说你写Java用了String类，你怎么保证你用的那个String类就是JDK里提供的那个String类呢？答案是对于JDK基础类，JDK要用特殊的ClassLoader来保证在正确的位置加载。
JDK主要有3个自带ClassLoader：
最基础：Bootstrap ClassLoader（加载JDK的/lib目录下的类）
次基础：Extension ClassLoader（加载JDK的/lib/ext目录下的类）
普通：Application ClassLoader（程序自己classpath下的类）

加载顺序
子类先委托父类加载
父类加载器有自己的加载范围，范围内没有找到，则不加载，并返回给子类
子类在收到父类无法加载的时候，才会自己去加载

破坏双亲委派（spi）
可以看出双亲委派机制是一种至下而上的加载方式，那么SPI是如何打破这种关系？
以JDBC加载驱动为例：
在JDBC4.0之后支持SPI方式加载java.sql.Driver的实现类。SPI实现方式为，通过ServiceLoader.load(Driver.class)方法，去各自实现Driver接口的lib的META-INF/services/java.sql.Driver文件里找到实现类的名字，通过Thread.currentThread().getContextClassLoader()类加载器加载实现类并返回实例。
驱动加载的过程大致如上，那么是在什么地方打破了双亲委派模型呢？
先看下如果不用Thread.currentThread().getContextClassLoader()加载器加载，整个流程会怎么样。

1、从META-INF/services/java.sql.Driver文件得到实现类名字DriverA
2、Class.forName(“xx.xx.DriverA”)来加载实现类
3、Class.forName()方法默认使用当前类的ClassLoader，JDBC是在DriverManager类里调用Driver的，当前类也就是DriverManager，它的加载器是BootstrapClassLoader。
4、用BootstrapClassLoader去加载非rt.jar包里的类xx.xx.DriverA，就会找不到
要加载xx.xx.DriverA需要用到AppClassLoader或其他自定义ClassLoader
5、最终矛盾出现在，要在BootstrapClassLoader加载的类里，调用AppClassLoader去加载实现类
这样就出现了一个问题：如何在父加载器加载的类中，去调用子加载器去加载类？
jdk提供了两种方式，Thread.currentThread().getContextClassLoader()和ClassLoader.getSystemClassLoader()一般都指向AppClassLoader，他们能加载classpath中的类
SPI则用Thread.currentThread().getContextClassLoader()来加载实现类，实现在核心包里的基础类调用用户代码

# spring actuator? 它有什么优势？

spring-boot-starter-actuator模块是一个spring提供的监控模块。我们在开运行发过程中，需要实时和定时监控服务的各项状态和可用性。Spring Boot的spring-boot-starter-actuator 模块（健康监控）功能提供了很多监控所需的接口，可以对应用系统进行配置查看、相关功能统计等。

# 项目遇到问题如何解决？

1. 项目偶尔HTTP请求过不来。 排查堆栈后没发现异常， 只能调大JVM参数

2.

- 登录用JWT做的。
- 权限是用拦截器做的。拦截URL 。 URL是在后台配置每个页面有那些URL，有那些权限
- 功能最大快是事件上报，有朗讯的电话+乙联的视频会议。
- 视频指挥调度， 就是我们所有的设备都是可以在我们页面上拉起来的。
最多支持9路视频。 包含语音对讲功能。
- 然后就是一些不重要的功能。各种物资的金销存调度，
企业行政执法，危险源等
- 有几张图用来展示这些数据，供用户调度。还有匹配预案的功能
相当于演习的功能提前布局的几种方式。
我主要负责，地图展示数据那块，跟后台的通讯服务维护
设备跟PC通讯是基于netty4开发的。
通道主要用的是netty的SimpleChannelUpstreamHandler
敲重点。理解这个
编解码用的是
平安深圳就是我们公司的推广项目
最大用户量有6W台设备在线。 我不是维护平安
项目的，但是我们应急项目规格跟他们是一样的
先说一下规定的格式吧。
固定包头p+包尾#
协议号占一个字节8位 +然后不定长包数据
主要就是写了 登录，
发送语音消息，
文字消息
上报位置，设置视频清晰度，心跳啥的。
这里主要用到了设计模式是模板模式+工厂模式，写一个抽象的类。
然后各种命令继承这个抽象类，抽象类有一个执行命令的方法。
比如登录就是L1类然后就反射生成子类。执行抽象类的方法。
通过一个工厂去判断命令号是什么然后反射生成什么类，这里
反射类用MAP做过缓存。为了不要每次都生成。
来一个指令就创建一个线程丢到线程池去执行。
无阻塞的，高并发的关键。
不过语音消息是单独的一个线程池，保证有序是用阻塞队列做的。然后用一个单线程去跑的
语音消息一般并发量不高，所以能承受。
序列化的话用了XXX

# 如何保证redis与数据库双写一直

延迟双删

# 分库分表后，ID主键如何处理

用UUID
要不就跳跃自增
雪花算法

# 搭建高并发网站

CDN
NG-LVS（虚拟服务器）
要不就用硬件F5
MYSQL

# 手画rabbitmq,kafka等流程图

# 消息堆积怎么处理

　几千万条数据在MQ里积压了七八个小时，最简单的方法可以让他恢复消费速度，然后等待几个小时消费完毕。

　　一个消费者一秒是1000条，一秒3个消费者是3000条，一分钟是18万条，1000多万条 ，所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概1小时的时间才能恢复过来

　　一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：

　　　　先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉

　　　　新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量

　　　　然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue

　　　　接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据

　　　　这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据

　　　　等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息

# rabbitmq,kafka源码

# spirng aop ioc 的理解

Spring
　　首先它是一个开源而轻量级的框架。其核心容器的主要组件是Bean工厂（BeanFactory）。Bean工厂使用控制反转（IOC）模式来降低程序代码之间的耦合度，并提供了面向切面编程（AOP）的实现。

　　正如其字面意思，是程序员的春天，大大地降低了体力劳动～

　　Spring 常用注解

　　1、@Component : 组件。标识这是个受 spring 管理的组件。（当组件不好归类时使用）

　　2、@Controller：用于标注控制层组件（如 struts 中的 action）。

　　　　　　使用这个注解，且不指定 value 的时候，默认 bean 的名字为类名首字母小写。

　　3、@Service：用于标注业务层组件。

　　4、@Repository：用于标注数据访问组件，即DAO组件。

　　5、@Scope("prototype") ：将Action的范围设置为原型（也就是多例的）。保证每一个请求有一个单独的 Action 来处理，避免 struts 中 Action 的线程问题。

　　　　　　由于 spring 默认是单例的，这种情况下，只会创建一个 Action 对象，每次访问都是同一个对象，数据不安全。Struts 要求必须是多例的，每次访问对应的不同的 Action 对象。这个注解相当于在 spring 中保证了这一点。

　　　　　　有问题啊：为什么 spring mvc 又是建议单例的呢？它不担心数据安全吗？　　-- 个人理解：我们表现层使用 struts 时建议是多例的原因是，Struts 是通过模型驱动和属性驱动来获取前端页面参数的，Action 里面存在大量成员变量，单例模式会导致属性重复使用，数据不安全。而 spring mvc 获取参数的模式是通过方法形参，一般之作用于方法，故不需要开启多例。

　　6、@Autowired：默认按类型进行自动装配。在容器查找匹配的Bean，当有且仅有一个匹配的Bean时，Spring将其注入@Autowired标注的变量中。

　　7、@Resource：默认按名称装配，当找不到与名称匹配的bean才会按类型装配。

AOP
　　　　-- Aspect-Oriented Programming 面向切面编程

　　前言：我们都知道 Java 是 OOP-面向对象编程的，它有自己的优势，也有自己的不足。比如说：在我们开发中，都会有一条业务主线（即客户的需求）。而我们要做的就是实现这个主线上的需求。我们在实现这些功能的时候，经常要干一些额外的不可避免的事情，比如事务的管理，日志的记录等，就很繁杂且代码量增多。

　　所以 Spring 提供了另一种角度来思考程序结构，也就是把这一些事情剥离出来，然后适时适地的把它们加入到我们的代码中，比如说 声明式事务管理的时候，我们在 service 层检测到save*、update*这些方法要被调用的时候，我们先进行开启事务什么的，这就是AOP，面向编程的思想。

　　总的来说，在运行时，动态地将代码切入到类的指定方法、指定位置上的编程思想就是面向切面的编程。

　　AOP 名词的大白话解说

　　1、通知　　--  Advice

　　　　就是要给目标类织入的事情。就是我们说的额外的一些共同的事情，也就是上面说的 事务，日志等。你给先定义好，然后在想用的地方用一下。

　　2、连接点　　-- JoinPoint

 　　　　就是 spring 允许你使用通知的地方，那可真就多了，基本每个方法的前，后（两者都有也行），或抛出异常时都可以是连接点，spring 的话只支持方法连接点。和方法有关的前前后后（抛出异常），都是连接点。一个类的所有方法前、后、抛出异常时等都是连接点。

　　3、切入点　　-- Pointcut

　　　　上面说的连接点的基础上，来定义切入点，你的一个类里，有15个方法，那就有几十个连接点了对把，但是你并不想在所有方法附近都使用通知（使用叫织入，下面再说），你只想让其中的几个，在调用这几个方法之前，之后或者抛出异常时干点什么，那么就用切点来定义这几个方法，让切点来筛选连接点，选中那几个你想要的方法。（比如需要开启事务的只是“ save *”、“ update* ”..等等这些方法）。切入点就是定义了哪个类里面的哪些方法的会得到通知。

　　4、切面　　-- Aspect

　　　　切面是通知和切入点的结合。现在发现了吧，没连接点什么事情，连接点就是为了让你好理解切点，搞出来的，明白这个概念就行了。通知说明了干什么和什么时候干（什么时候通过方法名中的before,after，around等就能知道），而切入点说明了在哪干（指定到底是哪个方法），这就是一个完整的切面定义。

　　5、织入　　-- weaving

　　　　把切面应用到目标对象来创建新的代理对象的过程。可以在编译时、类加载时、运行时完成的织入，spring 采用的是 在运行时完成织入。

　　6、引入　　-- introduction

　　　　允许我们向现有的类添加新方法属性。这不就是把切面（也就是新方法属性：通知定义的）用到目标类中吗~

　　7、目标　　-- target
.
　　　　引入中所提到的目标类，也就是要被通知的对象，也就是真正的业务逻辑，他可以在毫不知情的情况下，被咱们织入切面。而自己专注于业务本身的逻辑。

　　8、AOP 的代理　　-- AOP Proxy

　　　　目标对象被织入增强后产生的结果类。我的理解它是 spring 为了骗过 jvm 的类型检查，搞出来的一个伪装类。

　　　　spring 伪装采用了两种方式：

　　　　① 实现和目标类相同的接口　　-- 与目标类为双胞胎兄弟（要找我哥办事，弟弟我冒充哥哥收点礼物，再让我哥给你办事~）

　　　　② 生成子类调用　　-- 给目标类当儿子（学会了爸爸的本事，都找我办就好了，但是我要先收点礼物~）

IOC
　　　　-- Inversion of Control 控制反转

　　创建对象的控制权，被反转到了 spring 框架。意味着将你设计好的对象交给 spring 控制管理，而不是传统的在你的对象内部直接控制。

　　DI　　-- Dependency Injection  依赖注入

　　　　由 IOC 容器动态的将某个对象所需要的外部资源（包括对象、资源、常量数据）注入到组件( spring 中的组件如：controller, service..等）之中。

　　　　大白话：也就是 IOC 会把你当前对象所需要的外部资源动态的注入给你。

　　IOC 和 DI 　　-- “被注入对象依赖IOC容器配置依赖对象”。

　　　　大白话：首先控制反转，我们把对象的控制权交给了 spring 框架的 IOC 容器，所以我们要使用的话，就是依赖 IOC 容器给我们动态注入。

　　大白话解说IOC（控制反转）和DI（依赖注入）：

　　举个栗子！在 UserAction 中要用到 UserServiceImpl 中的方法，最初的方法是在 UserAction 中通过  UserService userService = new UserServiceImpl; 需要它的时候就 new 出来，控制权在自己手里，但是使用 Spring 后，UserAction 不用主动去创建 UserServiceImpl 的实例了，这个工作已经交给 Spring来做了。然后 你要用的时候再直接问 Spring 要，就可以拿来用了。

　　这个时候你就由原来的主动创建，变成了被动依赖 Spring 创建好之后给你的注入，才能使用。控制权已经反转给 Spring 了~

# spring bean 的生命周期

# spring mvc 简单原理

# spring 事务

# spring 源码

- spring core

- spring aop

- spring content

- spring task

- spring transtransaction

- spring mvc

# nginx 反向代理

# nginx 动静分离，与负载均衡实现

每个设备的状态设置为:

a)        down 表示单前的server暂时不参与负载

b)        weight 默认为1.weight越大，负载的权重就越大。

c)        max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误

d)        fail_timeout:max_fails次失败后，暂停的时间。

e)        backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。

 修改配置如下：

    upstream yangli.com {

       server 127.0.0.1:8888;

       #tomcat

       server 127.0.0.1:8080 backup;

       #resin

    }

# nginx 双活实现（keepalive）
